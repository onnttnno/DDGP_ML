{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Actor(object):\n",
    "    def __init__(self, n_observation, n_action, name='actor_net'):\n",
    "        self.n_observation = n_observation\n",
    "        self.n_action = n_action\n",
    "        self.name = name\n",
    "        self.sess = None\n",
    "        self.build_model()\n",
    "        self.build_train()\n",
    "        \n",
    "    def build_model(self):\n",
    "        activation = tf.nn.elu\n",
    "        kernel_initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "        kernel_regularizer = tf.contrib.layers.l2_regularizer(0.1)\n",
    "        default_dense = partial(tf.layers.dense,\\\n",
    "                                activation=activation,\\\n",
    "                                kernel_initializer=kernel_initializer,\\\n",
    "                                kernel_regularizer=kernel_regularizer)\n",
    "        with tf.variable_scope(self.name) as scope:\n",
    "            observation = tf.placeholder(tf.float32,shape=[None,self.n_observation])\n",
    "            hid1 = default_dense(observation,32)\n",
    "            hid2 = default_dense(hid1,64)\n",
    "            action = default_dense(hid2,self.n_action,activation=tf.nn.tanh,use_bias=False)\n",
    "            trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=self.name)\n",
    "        self.observation,self.action,self.trainable_vars = observation,action,trainable_vars\n",
    "        \n",
    "    def build_train(self,learning_rate = 0.0001):\n",
    "        with tf.variable_scope(self.name) as scope:\n",
    "            action_grads = tf.placeholder(tf.float32,[None,self.n_action])\n",
    "            var_grads = tf.gradients(self.action,self.trainable_vars,-action_grads)\n",
    "            train_op = tf.train.AdamOptimizer(learning_rate).apply_gradients(zip(var_grads,self.trainable_vars))\n",
    "        self.action_grads,self.train_op = action_grads,train_op\n",
    "        \n",
    "    def predict_action(self,obs_batch):\n",
    "        return self.action.eval(session=self.sess,feed_dict={self.observation:obs_batch})\n",
    "\n",
    "    def train(self,obs_batch,action_grads):\n",
    "        batch_size = len(action_grads)\n",
    "        self.train_op.run(session=self.sess,feed_dict={self.observation:obs_batch,self.action_grads:action_grads/batch_size})\n",
    "        \n",
    "    def set_session(self,sess):\n",
    "        self.sess = sess\n",
    "        \n",
    "    def get_trainable_dict(self):\n",
    "        return {var.name[len(self.name):]: var for var in self.trainable_vars}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Critic(object):\n",
    "    def __init__(self, n_observation, n_action, name='critic_net'):\n",
    "        self.n_observation = n_observation\n",
    "        self.n_action = n_action\n",
    "        self.name = name\n",
    "        self.sess = None\n",
    "        self.build_model()\n",
    "        self.build_train()\n",
    "        \n",
    "    def build_model(self):\n",
    "        activation = tf.nn.elu\n",
    "        kernel_initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "        kernel_regularizer = tf.contrib.layers.l2_regularizer(0.1)\n",
    "        default_dense = partial(tf.layers.dense,\\\n",
    "                                activation=activation,\\\n",
    "                                kernel_initializer=kernel_initializer,\\\n",
    "                                kernel_regularizer=kernel_regularizer)\n",
    "        with tf.variable_scope(self.name) as scope:\n",
    "            observation = tf.placeholder(tf.float32,shape=[None,self.n_observation])\n",
    "            action = tf.placeholder(tf.float32,shape=[None,self.n_action])\n",
    "            hid1 = default_dense(observation,32)\n",
    "            hid2 = default_dense(action,32)\n",
    "            hid3 = tf.concat([hid1,hid2],axis=1)\n",
    "            hid4 = default_dense(hid3,128)\n",
    "            Q = default_dense(hid4,1, activation=None)\n",
    "            trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=self.name)\n",
    "        self.observation,self.action,self.Q,self.trainable_vars= observation,action,Q,trainable_vars\n",
    "    \n",
    "    def build_train(self,learning_rate=0.001):\n",
    "        with tf.variable_scope(self.name) as scope:\n",
    "            Qexpected = tf.placeholder(tf.float32,shape=[None,1])\n",
    "            loss = tf.losses.mean_squared_error(Qexpected,self.Q)\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            train_op = optimizer.minimize(loss)\n",
    "        self.Qexpected,self.train_op = Qexpected,train_op\n",
    "        self.action_grads = tf.gradients(self.Q,self.action)[0]\n",
    "    \n",
    "    def predict_Q(self,obs_batch,action_batch):\n",
    "        return self.Q.eval(session=self.sess,\\\n",
    "                           feed_dict={self.observation:obs_batch,self.action:action_batch})\n",
    "    \n",
    "    def compute_action_grads(self,obs_batch,action_batch):\n",
    "        return self.action_grads.eval(session=self.sess,\\\n",
    "                               feed_dict={self.observation:obs_batch,self.action:action_batch})\n",
    "    def train(self,obs_batch,action_batch,Qexpected_batch):\n",
    "        self.train_op.run(session=self.sess,\\\n",
    "                          feed_dict={self.observation:obs_batch,self.action:action_batch,self.Qexpected:Qexpected_batch})\n",
    "    \n",
    "    def set_session(self,sess):\n",
    "        self.sess = sess\n",
    "        \n",
    "    def get_trainable_dict(self):\n",
    "        return {var.name[len(self.name):]: var for var in self.trainable_vars}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AsyncNets(object):\n",
    "    def __init__(self,class_name):\n",
    "        class_ = eval(class_name)\n",
    "        self.net = class_(2,1,name=class_name)\n",
    "        self.target_net = class_(2,1,name='{}_target'.format(class_name))\n",
    "        self.TAU = tf.placeholder(tf.float32,shape=None)\n",
    "        self.sess = None\n",
    "        self.__build_async_assign()\n",
    "    \n",
    "    def __build_async_assign(self):\n",
    "        net_dict = self.net.get_trainable_dict()\n",
    "        target_net_dict = self.target_net.get_trainable_dict()\n",
    "        keys = net_dict.keys()\n",
    "        async_update_op = [target_net_dict[key].assign((1-self.TAU)*target_net_dict[key]+self.TAU*net_dict[key]) \\\n",
    "                           for key in keys]\n",
    "        self.async_update_op = async_update_op\n",
    "    \n",
    "    def async_update(self,tau=0.01):\n",
    "        self.sess.run(self.async_update_op,feed_dict={self.TAU:tau})\n",
    "    \n",
    "    def set_session(self,sess):\n",
    "        self.sess = sess\n",
    "        self.net.set_session(sess)\n",
    "        self.target_net.set_session(sess)\n",
    "    \n",
    "    def get_subnets(self):\n",
    "        return self.net, self.target_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory(object):\n",
    "    def __init__(self,memory_size=10000):\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        self.memory_size = memory_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    def append(self,item):\n",
    "        self.memory.append(item)\n",
    "        \n",
    "    def sample_batch(self,batch_size=256):\n",
    "        idx = np.random.permutation(len(self.memory))[:batch_size]\n",
    "        return [self.memory[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def UONoise():\n",
    "    theta = 0.15\n",
    "    sigma = 0.2\n",
    "    state = 0\n",
    "    while True:\n",
    "        yield state\n",
    "        state += -theta*state+sigma*np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-25 08:04:03,309] Making new env: MountainCarContinuous-v0\n",
      "[2017-12-25 08:04:03,337] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/rponnt/tmp')\n",
      "[2017-12-25 08:04:03,344] Clearing 4 monitor files from previous run (because force=True was provided)\n",
      "[2017-12-25 08:04:03,357] Starting new video recorder writing to /home/rponnt/tmp/openaigym.video.9.14342.video000000.mp4\n",
      "[2017-12-25 08:04:03,803] Starting new video recorder writing to /home/rponnt/tmp/openaigym.video.9.14342.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, ep 0, score -0.077318, steps 1\n",
      "iter 999, ep 1, score -12.147138, steps 999\n",
      "iter 1353, ep 2, score 93.054029, steps 354\n",
      "iter 1354, ep 3, score 99.996403, steps 1\n",
      "iter 2353, ep 4, score -13.100097, steps 999\n",
      "iter 3352, ep 5, score -17.618180, steps 999\n",
      "iter 3353, ep 6, score -0.023006, steps 1\n",
      "iter 4134, ep 7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-25 08:05:19,583] Starting new video recorder writing to /home/rponnt/tmp/openaigym.video.9.14342.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4136, ep 7, score 88.959920, steps 783\n",
      "iter 5135, ep 8, score -15.479076, steps 999\n",
      "iter 5136, ep 9, score -0.000831, steps 1\n",
      "iter 5799, ep 10, score 91.495555, steps 663\n",
      "iter 6267, ep 11, score 93.617574, steps 468\n",
      "iter 6268, ep 12, score 99.998548, steps 1\n",
      "iter 7267, ep 13, score -17.591877, steps 999\n",
      "iter 8266, ep 14, score -16.082281, steps 999\n",
      "iter 8267, ep 15, score -0.004693, steps 1\n",
      "iter 9266, ep 16, score -13.124522, steps 999\n",
      "iter 9696, ep 17, score 92.555163, steps 430\n",
      "iter 9697, ep 18, score 99.948763, steps 1\n",
      "iter 10428, ep 19, score 90.473064, steps 731\n",
      "iter 11427, ep 20, score -15.352556, steps 999\n",
      "iter 11428, ep 21, score -0.043866, steps 1\n",
      "iter 12418, ep 22, score 83.822388, steps 990\n",
      "iter 13094, ep 23, score 89.604035, steps 676\n",
      "iter 13095, ep 24, score 99.924891, steps 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Parent directory of DDPG_netwerk_Class.ckpt doesn't exist, can't save.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ; No such file or directory\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Actor/Actor/dense/bias/Adam, Actor/Actor/dense/bias/Adam_1, Actor/Actor/dense/kernel/Adam, Actor/Actor/dense/kernel/Adam_1, Actor/Actor/dense_1/bias/Adam, Actor/Actor/dense_1/bias/Adam_1, Actor/Actor/dense_1/kernel/Adam, Actor/Actor/dense_1/kernel/Adam_1, Actor/Actor/dense_2/kernel/Adam, Actor/Actor/dense_2/kernel/Adam_1, Actor/dense/bias, Actor/dense/kernel, Actor/dense_1/bias, Actor/dense_1/kernel, Actor/dense_2/kernel, Actor_1/beta1_power, Actor_1/beta2_power, Actor_target/Actor_target/dense/bias/Adam, Actor_target/Actor_target/dense/bias/Adam_1, Actor_target/Actor_target/dense/kernel/Adam, Actor_target/Actor_target/dense/kernel/Adam_1, Actor_target/Actor_target/dense_1/bias/Adam, Actor_target/Actor_target/dense_1/bias/Adam_1, Actor_target/Actor_target/dense_1/kernel/Adam, Actor_target/Actor_target/dense_1/kernel/Adam_1, Actor_target/Actor_target/dense_2/kernel/Adam, Actor_target/Actor_target/dense_2/kernel/Adam_1, Actor_target/dense/bias, Actor_target/dense/kernel, Actor_target/dense_1/bias, Actor_target/dense_1/kernel, Actor_target/dense_2/kernel, Actor_target_1/beta1_power, Actor_target_1/beta2_power, Critic/Critic/dense/bias/Adam, Critic/Critic/dense/bias/Adam_1, Critic/Critic/dense/kernel/Adam, Critic/Critic/dense/kernel/Adam_1, Critic/Critic/dense_1/bias/Adam, Critic/Critic/dense_1/bias/Adam_1, Critic/Critic/dense_1/kernel/Adam, Critic/Critic/dense_1/kernel/Adam_1, Critic/Critic/dense_2/bias/Adam, Critic/Critic/dense_2/bias/Adam_1, Critic/Critic/dense_2/kernel/Adam, Critic/Critic/dense_2/kernel/Adam_1, Critic/Critic/dense_3/bias/Adam, Critic/Critic/dense_3/bias/Adam_1, Critic/Critic/dense_3/kernel/Adam, Critic/Critic/dense_3/kernel/Adam_1, Critic/dense/bias, Critic/dense/kernel, Critic/dense_1/bias, Critic/dense_1/kernel, Critic/dense_2/bias, Critic/dense_2/kernel, Critic/dense_3/bias, Critic/dense_3/kernel, Critic_1/beta1_power, Critic_1/beta2_power, Critic_target/Critic_target/dense/bias/Adam, Critic_target/Critic_target/dense/bias/Adam_1, Critic_target/Critic_target/dense/kernel/Adam, Critic_target/Critic_target/dense/kernel/Adam_1, Critic_target/Critic_target/dense_1/bias/Adam, Critic_target/Critic_target/dense_1/bias/Adam_1, Critic_target/Critic_target/dense_1/kernel/Adam, Critic_target/Critic_target/dense_1/kernel/Adam_1, Critic_target/Critic_target/dense_2/bias/Adam, Critic_target/Critic_target/dense_2/bias/Adam_1, Critic_target/Critic_target/dense_2/kernel/Adam, Critic_target/Critic_target/dense_2/kernel/Adam_1, Critic_target/Critic_target/dense_3/bias/Adam, Critic_target/Critic_target/dense_3/bias/Adam_1, Critic_target/Critic_target/dense_3/kernel/Adam, Critic_target/Critic_target/dense_3/kernel/Adam_1, Critic_target/dense/bias, Critic_target/dense/kernel, Critic_target/dense_1/bias, Critic_target/dense_1/kernel, Critic_target/dense_2/bias, Critic_target/dense_2/kernel, Critic_target/dense_3/bias, Critic_target/dense_3/kernel, Critic_target_1/beta1_power, Critic_target_1/beta2_power)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1572\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ; No such file or directory\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Actor/Actor/dense/bias/Adam, Actor/Actor/dense/bias/Adam_1, Actor/Actor/dense/kernel/Adam, Actor/Actor/dense/kernel/Adam_1, Actor/Actor/dense_1/bias/Adam, Actor/Actor/dense_1/bias/Adam_1, Actor/Actor/dense_1/kernel/Adam, Actor/Actor/dense_1/kernel/Adam_1, Actor/Actor/dense_2/kernel/Adam, Actor/Actor/dense_2/kernel/Adam_1, Actor/dense/bias, Actor/dense/kernel, Actor/dense_1/bias, Actor/dense_1/kernel, Actor/dense_2/kernel, Actor_1/beta1_power, Actor_1/beta2_power, Actor_target/Actor_target/dense/bias/Adam, Actor_target/Actor_target/dense/bias/Adam_1, Actor_target/Actor_target/dense/kernel/Adam, Actor_target/Actor_target/dense/kernel/Adam_1, Actor_target/Actor_target/dense_1/bias/Adam, Actor_target/Actor_target/dense_1/bias/Adam_1, Actor_target/Actor_target/dense_1/kernel/Adam, Actor_target/Actor_target/dense_1/kernel/Adam_1, Actor_target/Actor_target/dense_2/kernel/Adam, Actor_target/Actor_target/dense_2/kernel/Adam_1, Actor_target/dense/bias, Actor_target/dense/kernel, Actor_target/dense_1/bias, Actor_target/dense_1/kernel, Actor_target/dense_2/kernel, Actor_target_1/beta1_power, Actor_target_1/beta2_power, Critic/Critic/dense/bias/Adam, Critic/Critic/dense/bias/Adam_1, Critic/Critic/dense/kernel/Adam, Critic/Critic/dense/kernel/Adam_1, Critic/Critic/dense_1/bias/Adam, Critic/Critic/dense_1/bias/Adam_1, Critic/Critic/dense_1/kernel/Adam, Critic/Critic/dense_1/kernel/Adam_1, Critic/Critic/dense_2/bias/Adam, Critic/Critic/dense_2/bias/Adam_1, Critic/Critic/dense_2/kernel/Adam, Critic/Critic/dense_2/kernel/Adam_1, Critic/Critic/dense_3/bias/Adam, Critic/Critic/dense_3/bias/Adam_1, Critic/Critic/dense_3/kernel/Adam, Critic/Critic/dense_3/kernel/Adam_1, Critic/dense/bias, Critic/dense/kernel, Critic/dense_1/bias, Critic/dense_1/kernel, Critic/dense_2/bias, Critic/dense_2/kernel, Critic/dense_3/bias, Critic/dense_3/kernel, Critic_1/beta1_power, Critic_1/beta2_power, Critic_target/Critic_target/dense/bias/Adam, Critic_target/Critic_target/dense/bias/Adam_1, Critic_target/Critic_target/dense/kernel/Adam, Critic_target/Critic_target/dense/kernel/Adam_1, Critic_target/Critic_target/dense_1/bias/Adam, Critic_target/Critic_target/dense_1/bias/Adam_1, Critic_target/Critic_target/dense_1/kernel/Adam, Critic_target/Critic_target/dense_1/kernel/Adam_1, Critic_target/Critic_target/dense_2/bias/Adam, Critic_target/Critic_target/dense_2/bias/Adam_1, Critic_target/Critic_target/dense_2/kernel/Adam, Critic_target/Critic_target/dense_2/kernel/Adam_1, Critic_target/Critic_target/dense_3/bias/Adam, Critic_target/Critic_target/dense_3/bias/Adam_1, Critic_target/Critic_target/dense_3/kernel/Adam, Critic_target/Critic_target/dense_3/kernel/Adam_1, Critic_target/dense/bias, Critic_target/dense/kernel, Critic_target/dense_1/bias, Critic_target/dense_1/kernel, Critic_target/dense_2/bias, Critic_target/dense_2/kernel, Critic_target/dense_3/bias, Critic_target/dense_3/kernel, Critic_target_1/beta1_power, Critic_target_1/beta2_power)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"/home/rponnt/anaconda3/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/rponnt/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-3d749817c595>\", line 19, in <module>\n    saver = tf.train.Saver()\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 748, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 296, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 239, in save_op\n    tensors)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1163, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/rponnt/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): ; No such file or directory\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Actor/Actor/dense/bias/Adam, Actor/Actor/dense/bias/Adam_1, Actor/Actor/dense/kernel/Adam, Actor/Actor/dense/kernel/Adam_1, Actor/Actor/dense_1/bias/Adam, Actor/Actor/dense_1/bias/Adam_1, Actor/Actor/dense_1/kernel/Adam, Actor/Actor/dense_1/kernel/Adam_1, Actor/Actor/dense_2/kernel/Adam, Actor/Actor/dense_2/kernel/Adam_1, Actor/dense/bias, Actor/dense/kernel, Actor/dense_1/bias, Actor/dense_1/kernel, Actor/dense_2/kernel, Actor_1/beta1_power, Actor_1/beta2_power, Actor_target/Actor_target/dense/bias/Adam, Actor_target/Actor_target/dense/bias/Adam_1, Actor_target/Actor_target/dense/kernel/Adam, Actor_target/Actor_target/dense/kernel/Adam_1, Actor_target/Actor_target/dense_1/bias/Adam, Actor_target/Actor_target/dense_1/bias/Adam_1, Actor_target/Actor_target/dense_1/kernel/Adam, Actor_target/Actor_target/dense_1/kernel/Adam_1, Actor_target/Actor_target/dense_2/kernel/Adam, Actor_target/Actor_target/dense_2/kernel/Adam_1, Actor_target/dense/bias, Actor_target/dense/kernel, Actor_target/dense_1/bias, Actor_target/dense_1/kernel, Actor_target/dense_2/kernel, Actor_target_1/beta1_power, Actor_target_1/beta2_power, Critic/Critic/dense/bias/Adam, Critic/Critic/dense/bias/Adam_1, Critic/Critic/dense/kernel/Adam, Critic/Critic/dense/kernel/Adam_1, Critic/Critic/dense_1/bias/Adam, Critic/Critic/dense_1/bias/Adam_1, Critic/Critic/dense_1/kernel/Adam, Critic/Critic/dense_1/kernel/Adam_1, Critic/Critic/dense_2/bias/Adam, Critic/Critic/dense_2/bias/Adam_1, Critic/Critic/dense_2/kernel/Adam, Critic/Critic/dense_2/kernel/Adam_1, Critic/Critic/dense_3/bias/Adam, Critic/Critic/dense_3/bias/Adam_1, Critic/Critic/dense_3/kernel/Adam, Critic/Critic/dense_3/kernel/Adam_1, Critic/dense/bias, Critic/dense/kernel, Critic/dense_1/bias, Critic/dense_1/kernel, Critic/dense_2/bias, Critic/dense_2/kernel, Critic/dense_3/bias, Critic/dense_3/kernel, Critic_1/beta1_power, Critic_1/beta2_power, Critic_target/Critic_target/dense/bias/Adam, Critic_target/Critic_target/dense/bias/Adam_1, Critic_target/Critic_target/dense/kernel/Adam, Critic_target/Critic_target/dense/kernel/Adam_1, Critic_target/Critic_target/dense_1/bias/Adam, Critic_target/Critic_target/dense_1/bias/Adam_1, Critic_target/Critic_target/dense_1/kernel/Adam, Critic_target/Critic_target/dense_1/kernel/Adam_1, Critic_target/Critic_target/dense_2/bias/Adam, Critic_target/Critic_target/dense_2/bias/Adam_1, Critic_target/Critic_target/dense_2/kernel/Adam, Critic_target/Critic_target/dense_2/kernel/Adam_1, Critic_target/Critic_target/dense_3/bias/Adam, Critic_target/Critic_target/dense_3/bias/Adam_1, Critic_target/Critic_target/dense_3/kernel/Adam, Critic_target/Critic_target/dense_3/kernel/Adam_1, Critic_target/dense/bias, Critic_target/dense/kernel, Critic_target/dense_1/bias, Critic_target/dense_1/kernel, Critic_target/dense_2/bias, Critic_target/dense_2/kernel, Critic_target/dense_3/bias, Critic_target/dense_3/kernel, Critic_target_1/beta1_power, Critic_target_1/beta2_power)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3d749817c595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUONoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_obs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1592\u001b[0m               \"Parent directory of {} doesn't exist, can't save.\".format(\n\u001b[1;32m   1593\u001b[0m                   save_path))\n\u001b[0;32m-> 1594\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Parent directory of DDPG_netwerk_Class.ckpt doesn't exist, can't save."
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "max_episode = 200\n",
    "gamma = 0.99\n",
    "tau = 0.001\n",
    "memory_size = 10000\n",
    "batch_size = 256\n",
    "memory_warmup = batch_size*3\n",
    "max_explore_eps = 1000\n",
    "save_path = 'DDPG_netwerk_Class.ckpt'\n",
    "\n",
    "tf.reset_default_graph()\n",
    "actorAsync = AsyncNets('Actor')\n",
    "actor,actor_target = actorAsync.get_subnets()\n",
    "criticAsync = AsyncNets('Critic')\n",
    "critic,critic_target = criticAsync.get_subnets()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    actorAsync.set_session(sess)\n",
    "    criticAsync.set_session(sess)\n",
    "    env = gym.make('MountainCarContinuous-v0')\n",
    "    env = wrappers.Monitor(env,'./tmp/',force=True)\n",
    "    obs = env.reset()\n",
    "    iteration = 0\n",
    "    episode = 0\n",
    "    episode_score = 0\n",
    "    episode_steps = 0\n",
    "    noise = UONoise()\n",
    "    memory = Memory(memory_size)\n",
    "    while episode < max_episode:\n",
    "        print('\\riter {}, ep {}'.format(iteration,episode),end='')\n",
    "        action = actor.predict_action(np.reshape(obs,[1,-1]))[0]\n",
    "        if episode%3 == 0:\n",
    "            bootfroce=np.random.rand(0,1);\n",
    "            if bootfroce ==0:\n",
    "                action =-(action*p + (1-p)*next(noise))\n",
    "        else:\n",
    "            if episode<max_explore_eps: # exploration policy\n",
    "                p = episode/max_explore_eps\n",
    "                action = action*p + (1-p)*next(noise)\n",
    "            next_obs, reward, done,info = env.step(action)\n",
    "            memory.append([obs,action,reward,next_obs,done])\n",
    "            if iteration >= memory_warmup:\n",
    "                memory_batch = memory.sample_batch(batch_size)\n",
    "                extract_mem = lambda k : np.array([item[k] for item in memory_batch])\n",
    "                obs_batch = extract_mem(0)\n",
    "                action_batch = extract_mem(1)\n",
    "                reward_batch = extract_mem(2)\n",
    "                next_obs_batch = extract_mem(3)\n",
    "                done_batch = extract_mem(4)\n",
    "                action_next = actor_target.predict_action(next_obs_batch)\n",
    "                Q_next = critic_target.predict_Q(next_obs_batch,action_next)[:,0]\n",
    "                Qexpected_batch = reward_batch + gamma*(1-done_batch)*Q_next # target Q value\n",
    "                Qexpected_batch = np.reshape(Qexpected_batch,[-1,1])\n",
    "                # train critic\n",
    "                critic.train(obs_batch,action_batch,Qexpected_batch)\n",
    "                # train actor\n",
    "                action_grads = critic.compute_action_grads(obs_batch,action_batch)\n",
    "                actor.train(obs_batch,action_grads)\n",
    "                # async update\n",
    "                actorAsync.async_update(tau)\n",
    "                criticAsync.async_update(tau)\n",
    "        episode_score += reward\n",
    "        episode_steps += 1\n",
    "        iteration += 1\n",
    "        if done:\n",
    "            print(', score {:8f}, steps {}'.format(episode_score,episode_steps))\n",
    "            obs = env.reset()\n",
    "            episode += 1\n",
    "            episode_score = 0\n",
    "            episode_steps = 0\n",
    "            noise = UONoise()\n",
    "            if episode%25==0:\n",
    "                saver.save(sess,save_path)\n",
    "        else:\n",
    "            obs = next_obs\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
